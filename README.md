**Spark Assignment**

**Assignment-1**

-- Configured and added logger for assignment_1.

-- As per the spark assignment_1 they are user and transaction csv files.

-- Firstly Imported Sql functions and Created spark session.

-- Created function and read user and transaction csv files.

-- Created function and joined user and transaction files by using inner join.

-- **Question_1**-Getting unique location  by using groupBy,count functions.

-- **Question_2**-Getting product bought by using  groupBy,collect functions.

-- **Question_3**- Getting total spend by using groupBy,sum functions.

**Assignment-2**

-- Configured and added logger for assignment_2.

-- As per the spark assignment_2 they are ghtorrent text files.

-- Firstly imported Sql types and functions,spark session and Created spark session.

-- **Question_1**Created function and read ghtorrent text files.

-- **Question_2**-Counting total lines in the ghtorrent text files.

-- **Question_3**-Counting number of warn message by using filter and aggregate functions.

-- **Question_4**-Counting repositories in api client column by using filter and aggregate functions.

-- **Question_5**-Counting most HTTP requests by using groupBy,orderBy and aggregate functions.

-- **Question_6**-Counting most failed HTTP requests by using filter,groupBy,orderBy and aggregate functions.

-- **Question_7**-Counting most active hour by using groupBy,orderBy and aggregate functions.

-- **Question_8**-Counting most active repository by using groupBy,orderBy and aggregate functions.
